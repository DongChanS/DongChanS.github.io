---
layout : post
title : Acoustic model (1) - HMM (Hidden markov model)
author : Shin Dong Chan
category : 'Speech Recognition'
---

Edx에서 제공하는 Automatic speech recognition 강의와, 

http://www.inf.ed.ac.uk/teaching/courses/asr/lectures-2019.html 의 강의자료를 참고하였습니다.

## 1) Introduction

이전에는 음파에서 음성인식을 위하여 중요한 특성을 추출하는 과정인 MFCC에 대해서 배웠습니다.

이렇게 추출한 MFCC는 음성인식에 있어서 중요한 정보가 되는데요, 이번에는 음성인식을 위한 과정 중 하나인 Acoustic modeling에 대해서 알아봅시다.

### 목차

1. Acoustic model(1편)
2. Acoustic model의 핵심 : HMM(1편)
3. MLE : Maximum likelihood estimation(2편)
4. GMM-HMM의 MLE 추정 & Inference (2편)
5. Context dependent phones(3편)
6. DNN-HMM (4편)

3편부터는 WFST(Weighted Finite State Transducer)에 대해서 알고 있어야 이해하기가 편하기 때문에 2편이 끝나고 WFST를 먼저 소개하도록 하겠습니다.   



## 2) Acoustic model

### 2-1. Acoustic model

Acoustic model은 주어진 문장에 대한 음성의 특징벡터(ex, MFCC)의 분포(distribution)를 계산해주는 모델입니다.

예를 들면, `'나는 음성인식을 한다.'` 라는 문장을 발음할 때,

사람마다 가진 고유의 **높낮이**(음정)은 다를 수가 있어도, 

같은 문장을 발음하는데에 있어서 생기는 **음파의 형태**(음색)와 **목소리의 크기 변화**(음량)는 비슷한 패턴을 가질 것입니다.

그래서 Acoustic model은, 많은 사람들의 발화데이터를 통해서 주어진 문장을 발음할 때에 나오는 **특징벡터의 패턴을 파악**하는 모델이라고 할 수 있습니다.

### 2-2. HMM 기반의 Acoustic model

![1](https://user-images.githubusercontent.com/37765338/64064287-67041100-cc3a-11e9-8de5-0f199338dd1c.png)

Generative model : 주어진 Input에 따라서 Output을 **확률적으로** 생성할 수 있는 모델.

- Input : Utterance
- Output : Acoustics (음파의 음향적 특징)

Generative model을 사용하는 이유는 뭘까요??

<br>

음성인식의 목적은, 특징벡터로부터 가장 적절한 Utterance를 예측하는 것인데,

가장 간단한 방법은 특징벡터에 대한 각 Utterance의 조건부확률을 반환하는 모델을 잘 학습하여 그대로 사용하는 것입니다.

하지만,  그 조건부확률을 직접 모델링하기는 쉽지가 않습니다.

흔히 Classification task에 사용되는 Fully connected layer + softmax를 잘 설계하려고 생각해봐도 생각보다 만만하지가 않습니다. 

그래서 우회하는 방식을 택하게 됩니다.

생성모델을 이용해서 Marginal probability를 잘 설계할 수 있다면,  베이즈 룰에 근거하여 가장 적절한 Utterance를 예측할 수 있기 때문입니다.



## 3) Acoustic model의 핵심 : HMM

고전적으로 많이 사용되었던 모델은 GMM-HMM인데, 이는 Gaussian mixture model과 Hidden markov model의 줄임말입니다.

이 GMM의 단점을 극복하기 위해서 DNN을 이용한 DNN-HMM을 사용하기도 하는데, 어찌됬건 HMM은 아직도 사용되고 있습니다.

이번에는 왜 HMM이 Acoustic modeling에 그렇게도 사용되는지, 어떻게 사용되는지를 알아보도록 하겠습니다.

### 3-1. Hidden markov chain

먼저, Hidden markov model은 두개의 Stochastic process을 이용하여 어떤 현상을 모델링합니다.

* Stochastic process : Random variable들의 벡터

![4](https://user-images.githubusercontent.com/37765338/64064291-6b302e80-cc3a-11e9-81ca-9438af941cc2.png)

`X`는 **Markov process**입니다. 이는 직접적으로 관측이 되지 않기 때문에 **잠재변수**라고 부릅니다.

* [Markov process](https://en.wikipedia.org/wiki/Markov_chain) : Markov property를 따르는 Stochastic variable

  (우선 위의 링크를 읽으시고 Transition probability, State라는 키워드에 대해서 학습하실 것을 추천드립니다. 여기서는 이에 대해서 상세히 설명할 수 없습니다 ㅠㅠ)

  * Markov property : 현재의 Random variable은 **바로 이전**의 Random variable에만 의존하는 성질
  * 보통, Time-Homonogenuous markov chain을 사용하는데, 이는 Time에 따라서 Transition probability가 변하지 않는다고 가정하기 때문에, **Transition probability를 행렬으로 표현**할 수 있습니다.

* 직접적으로 관측이 되지 않는다 = HMM으로부터 직접 관측할 수 없다

  = HMM의 결과값으로 생성되지 않는다.

`Y`는 HMM이 생성하는 확률변수입니다. 다만, `Y`를 생성하는 데에는 **오직 `X`만 관여한다는 특징**이 있습니다.

* 그것도 모든 State가 아니라, 동일한 State의 X 확률변수만 관여한다는 점입니다.

  ![1-5](https://user-images.githubusercontent.com/37765338/70845409-a6750700-1e91-11ea-8f91-4a5e26ed8b4a.png)

  이는 매우 강력한 조건입니다. 일반적인 현상 (이를테면 직장인의 월급과 월 지출간의 관계)는 이런 조건을 만족하지 못하기 때문에, HMM을 통해서 모델링하게 되면 매우 위험할 수 있습니다. 

* 왜냐하면.. 월 지출은 자신의 월급 이외에도 다양한 외부 요인(ex, 부채)이 많을 뿐더러, 몇 년을 모아서 한번에 구매하는 경우도 있기 때문에, 바로 이전 달의 월급만으로는 잘 판단하기 힘들 것입니다.



### 3-2. 음성인식에서의 HMM을 설계하자.

어찌됬건 **특징벡터와 Utterance간의 관계**는 위에서 언급한 강력한 조건을 잘 만족하기 때문에 잘 모델링이 된다는 뜻일텐데요.

일단 왜 그런지를 알아보기 이전에, HMM 모델을 설계하는 작업부터 해봅시다.

우선 HMM의 Output(Y)은 MFCC를 비롯한 **특징벡터**입니다.

MFCC는 **시간에 따른** 벡터값을 가지는 행렬이기 때문에 MFCC를 사용한다면, **각 State는 시간**을 의미할 것입니다.

시간이라는 정보는 HMM을 설계하는 데에 있어 매우 중요한 단서입니다.

* 시간은 **반드시 증가**합니다. 

  => State는 반드시 증가하는 방향으로만 설계되어야 합니다.

* 한 MFCC가 반영하는 **시간은 한정**되어 있습니다.

  => 반드시 Absorbing state가 있어야 합니다. 만약 그렇지 않다면 영원히 HMM이 특징벡터를 생성하게 될 수도 있다는 뜻인데 이는 불가능합니다.

![3](https://user-images.githubusercontent.com/37765338/64064289-68353e00-cc3a-11e9-8dff-9ec64743b872.png)

* Ergodic markov chain : 어떤 Transition matrix의 거듭제곱이 존재하여 모든 행렬의 원소값이 양수가 될 때를 Ergodic이라고 합니다.

  (쉽게 말하면 어떤 State에서 다른 State로 언젠가는 이동할 수 있다는 것입니다.)

위의 단서에 적합한 모델이 하나 있습니다. 바로 left-to-right HMM입니다.

좋습니다. 결론적으로 State가 시간을 의미하니까 HMM의 잠재변수(`X`)도 **시간**을 의미하게 될텐데..

그러면 Hidden markov model에 Utterence의 정보를 어떻게 반영할까요?

먼저, **각 단어에 따른 Hidden markov model**들을 여러 개 만드는 방식을 생각해 볼 수 있습니다.

![1](https://user-images.githubusercontent.com/37765338/70845417-c1e01200-1e91-11ea-8e36-833fab7219ea.png)

그러면 해당 특징벡터가 들어오면 전부 HMM에 투입해보고, 가장 확률이 높은 HMM에 대한 단어를 예측값으로 생각하면 됩니다.

그런데 이러한 접근법은 몇 가지 치명적인 단점이 있습니다.

1. Scalable하지 않다.
   * 단어의 종류는 엄청 많기 때문입니다... HMM 엄청 많이 필요합니다
2. 각 단어마다의 사용 비율이 다르다.
   * 어찌됬건 HMM을 학습을 해야하는데, 사용비율이 낮은 단어에 대한 HMM은 잘 학습이 되지 않을 수 있습니다.

그래서 **기본 단위**를 사용해야합니다.

바로 음성의 기본 단위인 **Phoneme**입니다.

영어에서 Phoneme는 종류가 44가지이기 때문에 위의 문제를 만족할 수 있습니다.

* 왜 한글 기준이 아니냐면.. 대부분 개발된 HMM Toolkit이 영어 기준이기 때문입니다. 물론 한글 발음을 영어 Phoneme로 매칭할 수 있기 때문에 큰 문제는 되지 않습니다.

그렇게 각 Phoneme마다 HMM을 만들어서, 시간마다 Phoneme을 잘 예측한다면 나중에 단어로 합치는 과정도 필요하겠지요. 

그것을 Pronunciation model (발음사전)이라고 합니다. 

![1-2](https://user-images.githubusercontent.com/37765338/70845418-c4426c00-1e91-11ea-9dda-c5c1e7df5c32.png)



### 3-3. Phoneme based model의 문제점.

하지만, 각 Phoneme마다 HMM을 학습하면 문제점이 있습니다.

같은 Phoneme이어도 이전, 이후에 발음한 **주변 Phoneme에 따라서 발음이 다르기 때문**입니다.

따라서, 이러한 문제를 해결하려면 Phoneme가 아닌 **Phone마다 HMM**을 학습해야합니다.

* **Phone** : acoustic realization of phoneme, 즉 주변의 발음을 반영한 Phoneme입니다.
* Context-dependent phone이라고도 부릅니다.

![6](https://user-images.githubusercontent.com/37765338/64064293-6bc8c500-cc3a-11e9-8f37-7b174f70daa5.png)

결론적으로 하나의 Phone마다 하나의 HMM을 만드는 것이 바람직한데,

Phone을 만드는 대표적인 방법은 앞뒤에 발음한 phoneme을 고려하는 것입니다.

![7](https://user-images.githubusercontent.com/37765338/64064294-6bc8c500-cc3a-11e9-89eb-22658e9da8f3.png)

예를 들어서, `ax-b+ah`는 `b` 이전에는 `ax`, 이후에는 `ah`가 발음되었다는 것을 의미합니다. 



### 3-4. HMM은 음성인식에 적절한가?

그러면 이렇게 Phone based HMM을 설계했다면, 이는 음성인식에 적절한 모델일까요?

즉, 위에서 언급한 **강력한 조건**을 만족할까요??

사실 음성 자체는 그렇지 않습니다만.. 특징벡터는 그렇다고 할 수도 있습니다.

왜냐하면 특징벡터는 음성이 [quasi-stationary](https://en.wikipedia.org/wiki/Quasi-stationary_distribution)하다는 가정을 하고 만들어졌기 때문입니다.

(보충설명 필요)



### 3-5.  Transition probability의 의미

(설명 필요)