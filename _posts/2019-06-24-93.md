---
layout : post
title : Lab 6 - Deploying and Predicting with Cloud ML Engine (작성중)
author : Shin Dong Chan
category : 'ML Studyjam'
---

Lab 5를 통해서 대용량의 데이터를 잘 학습한 모델 파일을 생성할 수 있습니다.

이 모델 파일을 배포해서 End user가 API Call을 통해 우리 모델을 사용할 수 있도록 해봅시다!

## 1) Deploying and Predicting with Cloud ML Engine

### 1-1. Using Cloud ML Engine to deploy

![1 PNG](https://user-images.githubusercontent.com/37765338/60005241-11930d00-96a9-11e9-8914-87fe91896f24.png)

1. 클라이언트 : REST API call with input variables
2. input variables을 serving input function을 통해서 서빙함.
3. 기타 전처리 로직 + 모델 로직을 이용하여 deploy

### 1-2. Why Serving function is required?

![2 PNG](https://user-images.githubusercontent.com/37765338/60005243-122ba380-96a9-11e9-8505-7999fb76f881.png)

서빙할때는 training input function을 재사용할 수 없습니다. 

왜냐하면 모델이 기대하는 인풋과 유저에게 받는 인풋이 다를 수 있기 때문입니다.

- 트레이닝 인풋 타입과 serving 인풋 타입이 다름 (csv -> json)
- serving 인풋은 라벨이 필요없음

그래서 serving input function에는 따로 파싱하는 로직이 필요합니다. 

### 1-3. Serving & Deploy 과정

![3](https://user-images.githubusercontent.com/37765338/60005246-13f56700-96a9-11e9-896d-cd8f678b9d00.png)

첫번째로, serving_input_function를 만듭니다.

`ServingInputReceiver`에 대해서 공부하기

![4](https://user-images.githubusercontent.com/37765338/60005247-13f56700-96a9-11e9-88c3-6b86d724c7a8.png)

두번째로는 GCP에서 훈련된 모델 파일을 배포합니다.

모델 위치, 버전, 이름을 명시해주고 `gcloud ml-engine models crearte`를 하면 위에서 명시된 모델이 생성됩니다.

![5](https://user-images.githubusercontent.com/37765338/60005248-148dfd80-96a9-11e9-8522-d7ff3cdc82e3.png)

이제 모델이 배포되었고, Client는 API Call을 통해서 모델 예측을 할 수 있습니다.

1. Credential을 획득

2. 이용하고자 하는 version의 Google API와 동일한 버전을 `discovery.build()`로 정의해줘야함.

   - ML Engine, v1 버전

   