---
layout : post
title : Automatic Speech Recognition (6) - Acoustic model(2)
author : Shin Dong Chan
category : 'Automatic Speech Recognition'
---

Edx에서 제공하는 Automatic speech recognition 강의와, 

http://www.inf.ed.ac.uk/teaching/courses/asr/lectures-2019.html 의 강의자료를 참고하였습니다.

------

이번에는 **음성, 텍스트 데이터**를 통해서 GMM-HMM을 학습하고, inference하는 과정에 대해서 알아보도록 하겠습니다.

## 1) 목차

### 1. Maximum likelihood estimation

### 2. EM Algorithm

### 3. GMM-HMM의 Estimation & Inference (간략히)



## 2) Maximum likelihood estimation

### 2-1. Parameter estimation이란

일반적으로, DNN에서는 다량의 데이터를 통해서 매개변수들을 **학습**한다는 표현을 사용하는데,

GMM을 비롯한 통계학에서 쓰이는 모델들은 매개변수들을 **추정**한다는 표현을 사용합니다.

결론적으로 둘 다 **최적의 매개변수를 찾는다는** 점에서는 동일하지만,

추정이라는 단어의 뜻을 생각해보면 **진짜 참값**을 어림짐작하는 느낌입니다.

왜냐하면 [빈도론적 확률론](https://en.wikipedia.org/wiki/Frequentist_probability)에서는 전체 모집단의 데이터를 적절히 반영하고 있는 **진짜 참값**이 있다고 가정하기 때문입니다.

그래서 목표는 간단합니다.

일부 데이터(샘플)을 가지고 전체 모집단의 특성을 잘 반영하는 Parameter(진짜 참값)를 찾는 것입니다.

그것을 Parameter estimation이라고 부릅니다.

### 2-2. Maximum likelihood estimation

보통 매개변수를 추정하는 데 많이 쓰이는 방법은 Maximum likelihood estimation입니다.

말그대로 Likelihood를 최대화하는 것인데요,

Likelihood는 **샘플 데이터들이 존재할 확률이 어느정도인가?** 를 반환하는 함수입니다.

그렇기 때문에 Likelihood를 최대화 한다는 것은,

통계 모델의 **파라미터를 적절히 조절**하여 샘플 데이터가 존재할 확률을 최대화 한다는 것입니다.

그렇게 된다면, 모델이 샘플 데이터를 잘 대변할 수 있겠죠.

하지만, 모델은 샘플이 아닌 전체 모집단을 잘 대변하는게 목적이기 때문에 MLE 파라미터는 **Overfitting을 유발하는 주요 원인**이 되긴 합니다.

그렇지만 우리가 가지고 있는 것은 샘플 데이터뿐이기 때문에, 이는 대부분 상황에서 매우 합리적인 추정방식입니다.

(물론 Overfitting을 제한하기 위해서 Likelihood를 이용한 BIC(Bayesian information criterion) 과 같은 식을 사용하기도 합니다.)



## 3) EM Algorithm

https://www.cs.utah.edu/~piyush/teaching/EM_algorithm.pdf 을 참고하였습니다.

### 3-1. 왜 사용하는가?

어찌됬건 MLE를 계산하기 위해서는, Likelihood를 잘 구한 다음에 Likelihood를 각 파라미터에 대한 편미분의 값이 0이 되는 해를 찾아야 하는데요

문제는 이 편미분의 해를 쉽게 찾을 수 없는 경우입니다.

왜냐하면 **한 파라미터가 다른 파라미터에 의존**하고 있는 경우가 많기 때문입니다.

특히 GMM-HMM같이 잠재변수가 있는 경우에는 더더욱 그렇습니다. 이름부터가 잠재변수니까요.

EM 알고리즘은 이러한 잠재변수가 있으며, 잠재변수를 같이 반영할 때 최적화가 가능하다면 사용할 수 있는 알고리즘입니다.

![1](https://user-images.githubusercontent.com/37765338/64065319-2363d400-cc47-11e9-9fbf-3f923b9c0b9d.png)

### 3-2. 왜 EM (Expectation maximization)인가?

결론적으로 Likelihood의 **Lower bound**가 잠재변수와 파라미터에 대한 **Conditional expectation으로 표현**되기 때문입니다.

Likelihood를 직접적으로 증가시키지 않고, Lower bound를 증가시킴으로써 반사이익을 누리는 방법입니다.

![2](https://user-images.githubusercontent.com/37765338/64065320-23fc6a80-cc47-11e9-8ca9-aafbad937459.png)

- Jensen inequality에 의해서 Lower bound를 구함

![3](https://user-images.githubusercontent.com/37765338/64065321-23fc6a80-cc47-11e9-8e16-e8bae66c21d5.png)

![4](https://user-images.githubusercontent.com/37765338/64065322-23fc6a80-cc47-11e9-80d0-8dfd2f8aea45.png)

- Lower bound(Conditional Expectation)를 반복적으로 최대화시킴.

이러한 EM 알고리즘의 단점이라면, 

Conditional expectation을 최대화할 수 있는 잠재변수를 찾는 것이 상당히 까다롭고 초기값에 영향을 받는다는 점이 있겠습니다.



## 4) Inference & Estimation

너무 수식이 많기 때문에 간단하게만 설명하고, 자세한 내용은 링크를 첨부를 하겠습니다. 

### 4-1. 참고링크

- [참고링크1]([https://ratsgo.github.io/machine%20learning/2017/03/18/HMMs/](https://ratsgo.github.io/machine learning/2017/03/18/HMMs/)) : Hidden markov chain에 대한 큰 틀을 파악할 수 있는 링크입니다.

- [참고링크2](http://www.inf.ed.ac.uk/teaching/courses/asr/2018-19/asr03-hmmgmm-handout.pdf) : GMM-HMM의 파라미터 추정에 대한 직관적인 접근 (Posterior occupiation probability, Soft-count) 을 알려줍니다.
- Automatic speech recognition (Dong Yu, Li Deng) : Viterbi algorithm이나, Baum welch algorithm에 대한 수식을 본격적으로 알려줍니다.

### 4-2. Estimation

1. Likelihood 계산 : Forward algorithm

   - 순수 Observation sequence가 나타날 확률을 계산해야 하는데, 

     HMM 특성상 Observation의 확률은 Latent variable에 의존하기 때문에 Observation sequence의 확률을 계산하기 위해서는 모든 가능한 Latent variable에 대한 joint probability를 더해줘야합니다.

     ![5](https://user-images.githubusercontent.com/37765338/64065316-2068e380-cc47-11e9-8cf8-f99848f1727c.png)

     이런 방식은 계산량이 매우 크기 때문에 Dynamic programming 기반의 Forward algorithm을 사용합니다.

     ![6](https://user-images.githubusercontent.com/37765338/64065317-2068e380-cc47-11e9-83a2-82d91dcde3c3.png)

2. Likelihood estimation : EM 알고리즘

   - E-step 

     : 잠재변수에 대한 Conditional expectation을 분리하여 Transition probability에 대한 식과, Observation sequence에 대한 식으로 만듬

     ![7](https://user-images.githubusercontent.com/37765338/64065318-2068e380-cc47-11e9-8aa0-5041b1960b57.png)

     ![8_](https://user-images.githubusercontent.com/37765338/64065314-1fd04d00-cc47-11e9-8854-582ff08a9f53.png)

   - M-step

     : 각각 식을 편미분해서 Lower bound를 업데이트함.

### 4-3.  Inference : Viterbi algorithm

Inference는 잘 학습한 모델을 통해서 실제로 예측값을 도출하는 과정입니다.

음성인식에서는 음파의 특징벡터를 통해서 가장 합리적인 Utterance를 반환하는 것이라고 볼 수 있습니다.

GMM-HMM과 같은 생성모델에서는 직접적으로 특징벡터에 대한 Utterance의 확률을 모델링할 수 없기 때문에

특징벡터와 Utterance의 Joint probability를 최대화시키는 Utterance를 구합니다.

비터비 알고리즘은 두 단계로 나뉘어져 있습니다.

1. Dynamic programming을 이용해서 단계적으로 최댓값을 구하고 메모리에 저장하는 과정

   ![9_](https://user-images.githubusercontent.com/37765338/64065315-1fd04d00-cc47-11e9-8495-abfaedc4a57a.png)

2. Partial backtracking을 이용해서 최댓값이 되는 Latent variable을 역으로 추적하는 과정

물론 실제 음성인식에서는 Language model까지 반영해야하기 때문에 비터비알고리즘만으로는 되지 않지만, 비터비 알고리즘이 Inference에 쓰인다고 합니다.



