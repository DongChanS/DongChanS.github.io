---
layout : post
title : Acoustic model (1) - HMM (Hidden markov model)
author : Shin Dong Chan
category : 'Speech Recognition'
---

Edx에서 제공하는 Automatic speech recognition 강의와, 

http://www.inf.ed.ac.uk/teaching/courses/asr/lectures-2019.html 의 강의자료를 참고하였습니다.

## 1) Introduction

이전에는 음파에서 음성인식을 위하여 중요한 특성을 추출하는 과정인 MFCC에 대해서 배웠습니다.

이렇게 추출한 MFCC는 음성인식에 있어서 중요한 정보가 되는데요, 이번에는 음성인식을 위한 과정 중 하나인 Acoustic modeling에 대해서 알아봅시다.

### 목차

1. Acoustic model(1편)
2. Acoustic model의 핵심 : HMM(1편)
3. MLE : Maximum likelihood estimation(2편)
4. GMM-HMM의 MLE 추정 & Inference (2편)
5. Context dependent phones(3편)
6. DNN-HMM (4편)

3편부터는 WFST(Weighted Finite State Transducer)에 대해서 알고 있어야 이해하기가 편하기 때문에 2편이 끝나고 WFST를 먼저 소개하도록 하겠습니다.   


## 2) Acoustic model

### 2-1. Acoustic model

Acoustic model은 주어진 문장에 대한 음성의 특징벡터(ex, MFCC)의 분포(distribution)를 계산해주는 모델입니다.

예를 들면, `'나는 음성인식을 한다.'` 라는 문장을 발음할 때,

사람마다 가진 고유의 **높낮이**(음정)은 다를 수가 있어도, 

같은 문장을 발음하는데에 있어서 생기는 **음파의 형태**(음색)와 **목소리의 크기 변화**(음량)는 비슷한 패턴을 가질 것입니다.

그래서 Acoustic model은, 많은 사람들의 발화데이터를 통해서 주어진 문장을 발음할 때에 나오는 **특징벡터의 패턴을 파악**하는 모델이라고 할 수 있습니다.

### 2-2. HMM 기반의 Acoustic model

![1](https://user-images.githubusercontent.com/37765338/64064287-67041100-cc3a-11e9-8de5-0f199338dd1c.png)

Generative model : 주어진 Input에 따라서 Output을 **확률적으로** 생성할 수 있는 모델.

- Input : Utterance
- Output : Acoustics (음파의 음향적 특징)



## 3) Acoustic model의 핵심 : HMM

고전적으로 많이 사용되었던 모델은 GMM-HMM인데, 이는 Gaussian mixture model과 Hidden markov model의 줄임말입니다.

이 GMM의 단점을 극복하기 위해서 DNN을 이용한 DNN-HMM을 사용하기도 하는데, 어찌됬건 HMM은 아직도 사용되고 있습니다.

이번에는 왜 HMM이 Acoustic modeling에 그렇게도 사용되는지를 알아보도록 하겠습니다.

### 3-1. Hidden markov chain

먼저, Hidden markov model은 어떤 자연현상을 모델링하기 위해서 두개의 Stochastic process를 가지고 있는데요,

![4](https://user-images.githubusercontent.com/37765338/64064291-6b302e80-cc3a-11e9-81ca-9438af941cc2.png)

1. Markov chain (**Latent variable**)
2. Markov chain의 각 state에만 의존하는 Stochastic process  (**Observation**)

즉, 주어진 Observation sequence를 도출하는데에는 **잠재변수**가 관여한다는 것인데요,

잠재변수가 Markov assumption (다음 State의 확률은 바로 이전 State에 대해서만 의존)을 따른다는 것이 가장 큰 특징이라고 할 수 있겠죠.

예를 들어서, GMM-HMM은 이 Observation sequence에 대한 확률을 Gaussian mixture model로 모델링한 것입니다.

### 3-2. 음성인식에서의 HMM

음성인식의 경우에는 Observation이 특징벡터이며, 잠재변수는 하나의 phone입니다. 

![6](https://user-images.githubusercontent.com/37765338/64064293-6bc8c500-cc3a-11e9-8f37-7b174f70daa5.png)

**하나의 phone**이라는 말이 굉장히 중요합니다.

한 문장을 모델링하기 위해서 **여러개의 HMM을 연결**한다는 개념이기 때문이죠.

통계학 시간에서 Markov chain에 대해서 배우셨으면 일반적으로 Time-homogeneous라고 가정하기 때문에,

이걸 잘 사용해서 한 문장이 그대로 하나의 HMM가 되겠구나 생각하실 수도 있지만, 이것은 현실적으로 힘듭니다.

왜냐하면 Markov chain의 Transition probability를 설계하기 위해서는 **최대 State의 개수를 고정시켜야 하기 때문입니다.**

<br>

보통 음성인식에서는 HMM의 State 개수는 3개를 사용하는데요, 즉 3개의 State로 하나의 Phone을 표현하는 것이죠.

그런데, 드는 의문이 있을 것입니다.

> 하나의 Phone 으로 어떻게 3개의 State를 모델링하지??

답은 **Context-dependent phone**입니다.

![7](https://user-images.githubusercontent.com/37765338/64064294-6bc8c500-cc3a-11e9-89eb-22658e9da8f3.png)


하나의 State는 Left context의 phone,

하나의 State는 레이블된 phone,

하나의 State는 Right context의 phone을 사용하는 것입니다.

<br>

어찌됬건 중요한 것은,

자연어처리 분야에서 많이 사용되는 RNN이나 Transformer같은 모델과는 달리 Monophone HMM은 **각 Phone들의 Dependency를 모델링하지는 않는다**는 것입니다.

### 3-3. Left to right HMM

음성인식에서 사용되는 HMM은 보통 Left to right HMM입니다.

![3](https://user-images.githubusercontent.com/37765338/64064289-68353e00-cc3a-11e9-8dff-9ec64743b872.png)

* Ergodic markov chain : 어떤 Transition matrix의 거듭제곱이 존재하여 모든 행렬의 원소값이 양수가 될 때를 Ergodic이라고 합니다.

  (쉽게 말하면 어떤 State에서 다른 State로 언젠가는 이동할 수 있다는 것입니다.)

<br>

이는 매우 합리적으로 보입니다.

ex) `덜`이라는 글자를 발음할 때,

누군가는 `ㄷ -> ㅓ -> ㄹ` 이렇게 발음할 수도 있고,

누군가는 `ㄷ -> ㅓ -> ㅓ -> ㄹ` 이렇게 길게 발음할 수도 있을 것입니다.

하지만, `ㄷ -> ㅓ -> ㄷ -> ... ` 이렇게 되돌아가는 경우는 없기 때문입니다.

그에 비추어 보아서, 각 phone마다 transition probability는 **발음의 길이**와 연관된다고 추측할 수 있겠습니다.

<br>

결론적으로 HMM은 문장의 발음을 굉장히 잘 모델링한 모델이라고 볼 수 있습니다.

Language model처럼 문맥을 인식하는 것과는 다릅니다.

우리는 어디까지나 **음 그자체**를 모델링하는 Acoustic model에 대해서 다루기 때문에 

이 점에 대해서 항상 유념하셔야합니다.