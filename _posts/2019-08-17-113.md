---
layout : post
title : Signal processing 1) - Feature extraction
author : Shin Dong Chan
category : 'Speech Recognition'
---

## 1) Background

1. 취급하는 데이터의 형태에 따라서 Sample rate를 다르게 해야 한다!

   - 음악 신호(Music signal) : 보통 **44100Hz로 샘플링**되기 때문에 음악 신호가 22050 Hz 이상의 진동수를 가졌다면, 우리 귀에서 완벽히 들을 수가 없습니다.

   - 음성 신호 (Speech signal) : 하지만 음성 신호는 보통 8000Hz 이하의 진동수를 가졌기 때문에, **16000Hz의 Sample rate**를 주로 사용합니다.
   - 모바일 환경 : 휴대폰의 bandwidth (대역폭)은 3400Hz 이하이므로, **보통 8000Hz의 Sample rate**를 주로 사용합니다.

2. 음성 신호의 형태

   ![1](https://user-images.githubusercontent.com/37765338/63212762-2ee1d600-c144-11e9-9d93-b14cf80fd9dd.png)

   - ex) `stuff`  라는 단어는  `st` + `uh` + `f` 의 형태로 3개의 Syllable로 쪼갤 수 있습니다.
     - `st`, `f` : unvoiced sound
     - `uh` : voiced vowel
   - uh는 st나 f에 비해서 **주기적인 특성이 잘 드러남** : Voiced sound는 성대의 진동을 통해서 생성되기 때문에, 주기적으로 진동이 드러난다!
   - 파동을 결정짓는 두가지의 특성
     1. 성대의 진동 : 성도에서부터 발생한 공기 흐름
     2. 성도의 모양 :  특정 소리를 낼 때마다 성도의 모양이 바뀜
   - st나 f는 둘 다 unvoiced이기 때문에 성대의 진동은 없으나, **소리를 낼 때 성도의 모양이 달라지기 때문에** 구분할 수 있음



## 2) Feature extraction

음성신호를 처리하기 위해서 일단은 **디지털 데이터로 샘플링**을 한다고 배웠습니다.

그 이후에는 이 디지털 데이터에서 적절한 Feature를 추출해야 하는데요, 이번에는 그 Feature extraction 과정에 대해서 알아보겠습니다.

### 2-1. Short-time Fourier Analysis (1) 소개

#### \- 1. 서론

저번 시간에, 우리는 음성을 Frequency domain으로 분석하기 위해서 Fourier transform을 사용한다고 배웠습니다.

그런데, 이 Fourier transform의 단점이라 하면, 진동수에 대해서만 해석하다보니 시간에 대한 영향력을 무시한다는 것이겠죠. 이런 단점을 극복하기 위해서 짧은 시간 단위로 Fourier transform을 사용하여 **시간에 따른 진동수의 분포를 확인할 수 있도록** 할 것입니다. [출처](https://m.blog.naver.com/vmv-tech/220936084562)

#### \- 2. Short-time이란?

음파는 [non-stationary](https://en.wikipedia.org/wiki/Stationary_process) 신호입니다.

- Stationary process : Unconditional joint probabability distribution이 시간에 따라서 변하지 않는 stochastic process
- 만약 음파가 stationary 성질을 가지려면, **진폭의 분포가 시간에 따라서 항상 일정해야한다**는 소리인데, 현실적으로 그렇게 가정할 수는 없기 때문입니다.

하지만, 무작정 non-stationary라고 하면 수식을 만들기가 매우 힘들어지므로, 특정 짧은 구간 내에서는 음파가 Stationary하다고 가정하는 편입니다.

- 짧은 구간을 **Window(Frame)** 라고 부르는 편입니다.

보통, 한 Window의 길이는 25ms(밀리세컨드)입니다.

- 하지만, 각 Window들을 겹쳐서 10ms마다 window가 바뀌도록 합니다

  ![1](https://user-images.githubusercontent.com/37765338/63212766-2f7a6c80-c144-11e9-9ec2-488d17e016a3.jpg)

- 이렇게 Window를 겹치게 하면 더 좋은 Fourier analysis를 할 수 있다고 합니다.

#### \- 3. Window function을 이용한 음파의 추출

음파는 기본적으로 연속적인 데이터이기 때문에, 이 데이터에서 특성을 추출할 때에도 Edge effect가 없어야 합니다.

하지만, Window 단위로 샘플들을 분리하여 Fourier transform을 취하게 되면, 각 스펙트럼마다 Edge effect가 생기는 것은 어쩔 수가 없을 것입니다. 

이렇게 된다면 생성된 스펙트럼이 원본의 특성을 잘 반영하지 못한다고도 볼 수 있겠죠.

따라서 Edge effect를 보정하는 작업이 필요한데요. 이것을 보정하기 위해서 Window function을 사용합니다.

각 샘플의 진폭에다가 가중치 개념의 Window function을 곱하여 사용하는데요, Window function은 여러 종류가 있으나 주로 Hamming window를 많이 사용합니다.

- [Window function](https://en.wikipedia.org/wiki/Window_function)의 특징
  - Symmetric
  - 특정 구간에서만 값이 존재함
  - 중앙값에서 가장 값이 큼

Window의 경계에 있는 Sample들의 영향력을 최소화하기 위해서 중앙에 가중치를 높게 주는 편입니다.

- Window function을 이용한 샘플의 보정

  ```bash
  x_m[n] = w[n] x[m*N+n], n=0, 1, ..., L-1
  ```

  - `x_m[n]` :  Window function을 통해서 보정된 샘플의 진폭

    `w[n]` : window function

    `x` : 샘플링된 신호

  - `m` : Window index 

    `N` : Window shift in samples

    `n` : Sample index

    `L` : Window size in samples

#### \- 4. Discrete Fourier transform

저번 시간에 배웠던 Fourier transform은 연속인 아날로그 음파 데이터를 Frequency domain으로 해석하는 방법이었습니다.

이번에는 샘플링된 음파 데이터를 Frequency domain으로 해석하기 위해서 Discrete Fourier transform을 이용할 수 있습니다.

![5](https://user-images.githubusercontent.com/37765338/63212768-31dcc680-c144-11e9-8aaf-14d4cc82fa65.png)

아날로그 신호에 대한 Fourier transform을 통해서는 `X(f)`, 진동수에 대한 복소함수를 만들 수 있었는데, Discrete Fourier transform을 통해서는 진동수에 대한 복소수열(Complex sequence)를 도출할 수 있습니다.

역시, 복소수 값에는 magnitude(진폭) 과 phase information(각도) 성분이 포함되어 있지만, 특성 추출을 위해서는 phase information이 별로 중요하지 않으므로 `|X_m(k)|`만 있으면 됩니다.

- phase information에 대한 설명 [출처](https://www.researchgate.net/post/What_information_is_contained_in_the_phase_spectrum_of_a_signal2)

  > Amplitude and phase are both basic and independent informations about a signal after a harmonic decomposition. While the amplitude tells you how strong is a harmonic in a signal, the phase tells where this harmonic lies in time. Applied on your hearing, you can estimate the strength of the sirene of an rescue car (amplitude in the acoustic spectrum) and you can estimate the direction the car is coming from based on the phase (difference) of the sound coming into your ears. Simply, the amplitude ist the strength of a signal, the phase ist its time or direction appearance.

  

  : phase information은 해당 진동수의 신호가 어떤 시간대에 나타나는가를 알려주는 것인데, 어자피 Short time 구간 내에서 Fourier transformation을 하기 때문에 미묘한 시간 차이는 중요하지 않은 특성이라서 추출하지 않는 것 같습니다.



#### \-5. Log magnitude spectrogram

- Spectrogram : visual representation of the spectrum
- Spectrum : 해당 신호의 Discrete fourier transform

스펙트로그램은 다음과 같이 그릴 수 있습니다.

![6](https://user-images.githubusercontent.com/37765338/63212767-30130300-c144-11e9-9f7d-2fe0fa763560.png)

![5](https://user-images.githubusercontent.com/37765338/63212768-31dcc680-c144-11e9-8aaf-14d4cc82fa65.png)

- x축 : frame index, 위 식에서 `m`
- y축:  frequency (0 ~ Nyquist frequency), 위 식에서 `k`
- 색깔 : 진폭의 크기, 높을 수록 붉은색을 띕니다. 위 식에서 `|X_m[k]|`



위 스펙트로그램과 Time domain에서의 그래프와 매칭을 시켜보면,

![1](https://user-images.githubusercontent.com/37765338/63212762-2ee1d600-c144-11e9-9d93-b14cf80fd9dd.png)

- `st` : unvoiced consonant => 에너지 높음 & 진동수 낮음
- `uh` : voiced vowel => 에너지 높음 & 진동수 높음
- 그 외 신호 => 에너지 낮음

으로 볼 수 있겠습니다.