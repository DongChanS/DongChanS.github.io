---
layout : post
title : Edwith 베이지안딥러닝 (2) random process
author : Shin Dong Chan
tags : ['Edwith']
---

첫번째 포스트를 너무 무리하게 쓰다가 시간이 너무 많이 걸려서

두번째부터는 상세하게 설명하지 않고 정리하는 식으로 적겠습니다.

<br>

### Conditional expectation

1. Conditional expectation E(X|Y)는 Random Variable Y에 대한 함수이다.

   즉 이 함수도 Random Variable이라고 할 수 있다.

2. 우리는 확률을 얘기하기 위해서 Sigma field를 고려해야하는데, 두 Random variable에서 underlying된 sigma field가 다를 수 있다는 것이다. 그럴 경우에는 measure를 정의를 할 수가 없다.

   (정확히 말하면 Y의 sigma field가 X에 대한 sigma field의 sub-sigma field가 되어야 한다. 즉, Y가 가질 수 있는 값들이 X가 가질 수 있는 범위안에 포함되어야 한다는 것)
   
![3](https://user-images.githubusercontent.com/37765338/50736577-6aa5dc00-1202-11e9-9933-cefd888a0f03.PNG)

   [여담]어떤 함수가 measurable이라는 개념이 등장하는데, 크게 중요한 조건은 아닙니다. (르벡적분을 하기 위한 기본적인 조건입니다.) 

   almost surely는 수학적으로 정의된 표현이긴 하지만 그냥 영어 그대로 받아들이셔도 됩니다.

3. 즉, Conditional expectation은 Y에 대한 역상 Y-1(y) 하에서 X의 평균을 구한 것이다.  따라서, Y의 정보가 많지 않아서 Y에 대한 역상이 Sample space를 크게 나눈다면 X에 대한 정보 역시 많이 얻을 수 없는 것이다.

![1](https://user-images.githubusercontent.com/37765338/50736575-6aa5dc00-1202-11e9-8bea-467da500de07.PNG)

4. 만약 Y가 우리의 data고, X가 우리가 찾고자 하는 distribution(Model)이라고 한다면, 데이터가 많아야 X에 대한 정보를 많이 얻을 수 있을 것이다.

<br>

#### Momentum&independence

- 기본적으로 두 분포가 같다 <=> 모든 momentum이 같다.

- 따라서 분포의 유사성을 검증하기 위해서는 평균 뿐만 아니라 적어도 분산,skewness(왜도),kurtosis(첨도) 정도는 비교해야한다.

- Joint moment (covariance, correlation)도 생각해 볼 수 있는데, correlated와 independent는 많이 다른 개념이다.

- 두 Random Variable이

  1. Uncorrelated :  두 random variable에 대한 평균의 곱이 보존되는 것이다. 

  2. Independent :  두 random variable 들로부터 생성되는 모든 set에 대해서 확률메져의 값이 independent 해야한다.

     => 2번조건이 훨씬 더 까다로운 조건입니다.

![2](https://user-images.githubusercontent.com/37765338/50736576-6aa5dc00-1202-11e9-97a1-87908782e949.PNG)

<br>

## Random process(Stochastic process)

### 1.정의

Random variable의 확장판.

여러 Random variable을 한꺼번에 생각하고싶다.

유한개의 r.v라면 단순히 벡터로 묶어서 나타낼 수 있겠지만,

만약 무한차원이라면 어떻게 표현할까?

-> **무한차원의 벡터**는 **함수**로 생각할 수 있기 때문에 무한개의 r.v를 함수로 묶어서 표현하는 방식을 취할 수 있다.

-> 이것을 Random process라고 한다( 물론 유한차원일때도 가능하다! )

[용어1] **Index set** : 각각의 r.v에 매기는 index들의 집합이다. (당연히 1차원일 필요는 없다.)

![4](https://user-images.githubusercontent.com/37765338/50736578-6b3e7280-1202-11e9-8df3-6aaadaee132e.PNG)

각각의 r.v도 함수이기때문에 Random process는 **Real line(index set)과 Sample space의 곱집합에서 정의되는 함수로 표현**할 수 있다.

<br>

하지만 복잡한 점이 많다. 하나의 r.v는 관리하기가 쉬웠지만, r.v가 여러개가 모이면 각각의 dependency를 고려해야 하기 때문에 그에 대한 확률을 측정하기가 쉽지 않은데, 아무튼 모든 r.v들의 벡터에 대해서 확률을 정의할 수 있어야 비로소 우리는 Random process를 만들었다고 할 수 있다.

![5](https://user-images.githubusercontent.com/37765338/50736579-6b3e7280-1202-11e9-9d28-72c3554ee762.PNG)

무한차원을 얘기하긴 했으나, 가변적으로 존재하는 모든 유한한 r.v들에 대한 벡터를 확률로 표현할 수 있다면 이 Random process를 표현하기에 충분하다고 한다.

[용어2] Sample path : Sample을 고정할 때, index set에 대한 random process를 말한다.

<br>

### 2.분류

이전 포스트에서 r.v는 Discrete r.v와 Continuous r.v로 분류할 수 있다고 했다.

이는 r.v가 가지는 값의 형태가 연속적이냐 이산적이냐에 따라 분류한 것인데,

<br>

random process는  Index set가 추가되었으므로 **Index set의 형태에 따라서 Discrete-time과 Continuous-time로 분류**할 수 있다.

왜 굳이 time이라고 하냐면, 보통 Ramdom process를 어떤 실험의 시행횟수(ex, Markov chain)나 시간의 흐름(ex, Brownian motion)에 따라서 정의하여 랜덤한 상황을 시뮬레이션하기 때문이다.

<br>

### 3.**Gaussian process**

Gaussian process는 이름 그대로 정규분포에 대한 Random process이다.

최근 딥러닝에서 많이 쓰이는 [GAN1](https://brunch.co.kr/@kakao-it/145)[GAN2](https://brunch.co.kr/@kakao-it/162) 도 여러 차원의 Gaussian process를 통해서 가짜 데이터를 생성하는데, Gaussian process는 특유의 성질에 의해서 많이 쓰인다.

- 특유의 성질

  1) Centural limit theorem : Random sample의 수가 한없이 늘어나면, 그 표본평균은 근사적으로 정규분포를 따른다

  -> 이건 노이즈를 모델링하기 위해서 쓰임.

  2) mean과 variance(물론 Covariance matrix)만 알면 Gaussian distribution을 표현할 수 있다.

  이와 비슷하게, 하나의 Gaussian process를 표현하기 위해서 **mean function과 auto-correlation function들만 알면 된다!**

[용어3,4] mean function, auto-correlation function(acf)

![6](https://user-images.githubusercontent.com/37765338/50736570-6974af00-1202-11e9-820b-8aac43990268.PNG)

acf는 다른 시간에 대한 두 r.v에 대한 correlation이라고 생각하면된다. 

acf는 머신러닝에서 보는 커널함수와 완전히 동일하다고하는데.. 커널함수를 잘 몰라서 공부해야할것같다..

<br>

### Stationarity

좀 더 분석하기 쉬운 random process에만 집중하기 위해서 좋은 성질을 만족하는 것만 생각하고 싶음. Stationarity가 대표적인 좋은 성질이다.

[용어5] Stationary

![7](https://user-images.githubusercontent.com/37765338/50736571-6a0d4580-1202-11e9-8c3c-34f7cc378d3a.PNG)

Stationary는 Random process가 시간에 대한 평행이동에 의존하지 않는다는 말이다.

(shift-invariant 혹은 translation-invariant라고 부르기도 함.)

이런 성질을 확률에 대해서 보이기는 쉽지 않으므로 몇개의 moment에 대해서 Stationary한 성질을 만족하는 것을 찾고 싶다.

![8](https://user-images.githubusercontent.com/37765338/50736572-6a0d4580-1202-11e9-882a-7b550d8a50ad.PNG)

(R은 auto-correlation function, C는 auto-covariance function이다.)

![9](https://user-images.githubusercontent.com/37765338/50736573-6a0d4580-1202-11e9-978b-ffcc1541101e.PNG)

=> mean function이 **상수**이며,

auto-correlation function이 **두 시간차에 대한 함수**가 된다. 


결론: 임의의 시간들에 대한 출력값들의 분포를 정의할 수 있어야 random process를 만들 수 있는데, stationary라는 성질을 가지고 있다면, **시간차에 대한 정보만으로도 random process를 만들 수 있다**. 그리고, Random process의 부드러운 정도가 auto-correlation function으로 표현될 수 있다.
