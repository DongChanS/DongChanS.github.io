---
layout : post
title : Studyjam 4) Lab 6 - Deploying and Predicting with Cloud ML Engine
author : Shin Dong Chan
category : 'ML Studyjam'
---

Lab 5를 통해서 대용량의 데이터를 잘 학습한 모델 파일을 생성할 수 있습니다.

이 모델 파일을 배포해서 End user가 API Call을 통해 우리 모델을 사용할 수 있도록 해봅시다!

## 1) Deploying and Predicting with Cloud ML Engine

### 1-1. Using Cloud ML Engine to deploy

![1 PNG](https://user-images.githubusercontent.com/37765338/60005241-11930d00-96a9-11e9-8914-87fe91896f24.png)

클라이언트 입장:
1. Call REST API with input variables
2. input variable을 CloudML에 serving
3. Cloud에 배포된 Model을 통하여 예측값 도출 

그러니까 이제 할 것은 2가지가 남았는데요.

1. input variable을 Serving 하는 로직을 만들기.
2. 모델을 배포하기 ( = REST API Call을 만들기 ) 입니다.

### 1-2. Why we should make Serving input function 

근데 왜 input을 그대로 쓰면 안되고 따로 Serving function을 거쳐야할까요?

![2 PNG](https://user-images.githubusercontent.com/37765338/60005243-122ba380-96a9-11e9-8505-7999fb76f881.png)

왜냐하면 모델이 기대하는 인풋과 유저에게 받는 인풋이 다를 수 있기 때문입니다.

따라서 서빙할때는 training input function을 재사용할 수 없습니다. 

- 트레이닝 인풋 타입과 serving 인풋 타입이 다름 (csv -> json)
- serving 인풋은 라벨이 필요없음

그래서 serving input function에는 따로 파싱하는 로직이 필요합니다. 

### 1-3. Serving & Deploy 과정

![3](https://user-images.githubusercontent.com/37765338/60005246-13f56700-96a9-11e9-896d-cd8f678b9d00.png)

첫번째로, serving_input_function를 만듭니다.

![4](https://user-images.githubusercontent.com/37765338/60005247-13f56700-96a9-11e9-88c3-6b86d724c7a8.png)

두번째로는 GCP에서 잘 학습된 모델 파일을 배포합니다.

모델 위치, 버전, 이름을 명시해주고 `gcloud ml-engine models crearte`를 하면 위에서 명시된 모델이 생성됩니다.

![5](https://user-images.githubusercontent.com/37765338/60005248-148dfd80-96a9-11e9-8522-d7ff3cdc82e3.png)

이제 모델이 배포되었고, Client는 API Call을 통해서 모델 예측을 할 수 있습니다.

1. Credential을 획득

2. 이용하고자 하는 version의 Google API와 동일한 버전을 `discovery.build()`로 정의해줘야함.

   

